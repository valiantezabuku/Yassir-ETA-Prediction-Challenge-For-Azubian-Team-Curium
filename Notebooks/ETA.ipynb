{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRFyZXFY3KFw"
      },
      "source": [
        "# Business Understanding\n",
        "\n",
        "##### **Overview**\n",
        "\n",
        "Yassir is the leading super App in the Maghreb region set to changing the way daily services are provided. It currently operates in 45 cities across Algeria, Morocco and Tunisia with recent expansions into France, Canada and Sub-Saharan Africa. It is backed (~$200M in funding) by VCs from Silicon Valley, Europe and other parts of the world. They offer on-demand services such as ride-hailing and last-mile delivery.\n",
        "\n",
        "##### **Project Scenario**\n",
        "\n",
        "Ride-hailing apps like Uber and Yassir depend heavily on real-time data and machine learning algorithms to automate and optimize their services. Accurate prediction of the Estimated Time of Arrival (ETA) is crucial for enhancing the reliability and attractiveness of Yassir's services. This prediction will have significant direct and indirect impacts on both customers and business partners. Improving ETA predictions will not only make Yassir's services more dependable but also allow the company to save money and allocate resources more effectively across other business areas.\n",
        "\n",
        "##### **Problem Statement**\n",
        "\n",
        "Yassir aims to optimize its service operations by accurately predicting the ETA for rides. The goal is to ensure that customers receive precise arrival times, improving their overall experience while allowing Yassir to manage resources more effectively and reduce operational costs.\n",
        "\n",
        "##### **Objective**\n",
        "\n",
        "The primary objective of this project is to develop machine learning models that accurately predict the ETA for a Yassir journey to enhance service reliability and customer satisfaction. By accurately forecasting the time it will take for a trip to reach its destination, Yassir can improve the customer experience, optimize operational efficiency, and better manage resource allocation. This will contribute to cost savings and more efficient use of resources, benefiting both customers and business partners.\n",
        "\n",
        "##### **Key Stakeholders**\n",
        "\n",
        "Stakeholders include Yassir's management team, operations and logistics teams, customer service department, and data science team.\n",
        "\n",
        "##### **Analytical Goals**\n",
        "\n",
        "1. **Data Preparation:**\n",
        "   - Handle missing values in trip and weather datasets using imputation techniques such as mean, median, or mode.\n",
        "   - Address outliers in trip data that may skew model predictions by applying robust statistical methods.\n",
        "   - Normalize or scale numerical features (e.g., trip distance) to ensure uniformity and improve model performance.\n",
        "   - Encode categorical variables (e.g., weather conditions) using one-hot encoding or similar techniques.\n",
        "\n",
        "2. **Model Development:**\n",
        "   - Train and evaluate various regression models such as linear regression, decision trees, random forests, and gradient boosting algorithms.\n",
        "   - Incorporate time series analysis if applicable to capture temporal trends and seasonality.\n",
        "   - Validate models using cross-validation techniques and assess performance metrics such as RMSE (Root Mean Squared Error).\n",
        "\n",
        "3. **Feature Engineering:**\n",
        "   - Extract relevant features from timestamps (e.g., time of day, day of week) and weather conditions to enrich the model.\n",
        "   - Analyze feature importance to understand key factors affecting ETA predictions.\n",
        "\n",
        "4. **Visualization and Reporting:**\n",
        "   - Create visualizations and dashboards to present insights from the model and its predictions.\n",
        "   - Develop a deployment strategy for integrating the ETA prediction model into Yassir’s operational systems.\n",
        "\n",
        "##### **Success Criteria**\n",
        "\n",
        "1. Achieve a significant reduction in ETA prediction errors, with an RMSE below 200.\n",
        "2. Develop a functional data app that embeds the best models and makes accurate prediction of ETA.\n",
        "\n",
        "##### **Constraints and Assumptions**\n",
        "\n",
        "- Assumption: Historical trip and weather data are representative of future conditions and trends.\n",
        "- Constraint: Limited availability of real-time traffic data for model refinement and updates.\n",
        "\n",
        "##### **Data Requirements**\n",
        "\n",
        "- Utilize data from trip records and weather datasets for analysis.\n",
        "- Include features such as trip ID, timestamp, origin and destination coordinates, trip distance, ETA, and weather conditions (temperature, rainfall, wind speed).\n",
        "\n",
        "##### **Business Impact**\n",
        "\n",
        "- **Enhanced Customer Experience:** More accurate ETA predictions will improve customer satisfaction and trust in Yassir’s services.\n",
        "- **Operational Efficiency:** Better predictions will optimize driver allocation and reduce operational costs.\n",
        "- **Resource Allocation:** Improved resource management through accurate trip scheduling and reduced delays.\n",
        "- **Cost Savings:** Financial savings from reduced inefficiencies and optimized resource use.\n",
        "\n",
        "##### **Analytical Business Questions**\n",
        "\n",
        "1. What is the impact of trip distance on ETA accuracy?\n",
        "   Investigating whether longer or shorter trips have more variance in ETA predictions can help refine the model.\n",
        "2. How do different times of the day affect ETA.\n",
        "   Analyzing time-based patterns (e.g., rush hours vs. non-rush hours) can help improve the predictive model.\n",
        "3. How does weather impact the estimated time of arrival (ETA) for Yassir trips?\n",
        "4. What are the peak hours for long trip durations and how can they be optimized?\n",
        "5. Is there a significant difference in trip durations between weekdays and weekends?\n",
        "6. How does the density of trips in a given area affect the performance of the ETA prediction?\n",
        "7. How does the model's ETA prediction accuracy compare to industry benchmarks or competitors?\n",
        "8. How does the time of day influence the demand for Yassir rides in different geographical areas?\n",
        "9. Which origin and destination locations are most common?/Have the most rides\n",
        "10. What are the longest and shortest trips, and how do their ETAs compare?\n",
        "11. What is the percentage of trips with ETAs exceeding 30 minutes.\n",
        "12. What is the average number of trips per hour?\n",
        "   \n",
        "\n",
        "#### **Hypothesis**\n",
        "\n",
        "**Null Hypothesis:** The demand for Yassir rides is significantly higher during peak traffic hours compared to non-peak hours.\n",
        "\n",
        "**Alternate Hypothesis:** There is no significant difference in ride demand between peak traffic hours and non-peak hours.\n",
        "\n",
        "#### Recomendations\n",
        "1. Improve customer satisfaction scores related to ride accuracy.\n",
        "2. Optimize driver allocation and resource management, leading to cost savings and operational efficiency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xle9gmbW3KF0"
      },
      "source": [
        "# Data Understanding\n",
        "\n",
        "`Dataset Overview:`\n",
        "\n",
        "- ID: Unique identifier for each trip.\n",
        "        \n",
        "- Timestamp: Time when the trip started.\n",
        "    \n",
        "- Origin_lat, Origin_lon: Latitude and longitude of the trip's start location.\n",
        "\n",
        "- Destination_lat, Destination_lon: Latitude and longitude of the trip's end location.\n",
        "\n",
        "- Trip_distance: Distance in meters on the driving route.\n",
        "\n",
        "- ETA: Estimated trip time in seconds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0tE1W5eCXT0"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet plotly_calplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNW5g2AH3KF0"
      },
      "outputs": [],
      "source": [
        "# Data Wrangling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Visualization\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly_calplot import calplot\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# PCA\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Stats test and Normality\n",
        "from scipy.stats import ttest_ind, shapiro, mannwhitneyu\n",
        "\n",
        "# Modelling\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler\n",
        "from sklearn.metrics import roc_curve, auc, mean_squared_error, root_mean_squared_error\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "# Save model\n",
        "import joblib\n",
        "\n",
        "# Set pandas to display all columns\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "\n",
        "# Suppress the scientific notation\n",
        "pd.set_option(\"display.float_format\", lambda x: '%.2f' % x)\n",
        "\n",
        "# Disable warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"🛬 Imported all packages.\", \"Warnings hidden. 👻\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPdDgmPZ-lNJ"
      },
      "outputs": [],
      "source": [
        "TEST_FILE = \"https://raw.githubusercontent.com/valiantezabuku/Yassir-ETA-Prediction-Challenge-For-Azubian-Team-Curium/main/Data/Test.csv\"\n",
        "TRAIN_FILE = \"https://raw.githubusercontent.com/valiantezabuku/Yassir-ETA-Prediction-Challenge-For-Azubian-Team-Curium/main/Data/Train.csv\"\n",
        "WEATHER_FILE = \"https://raw.githubusercontent.com/valiantezabuku/Yassir-ETA-Prediction-Challenge-For-Azubian-Team-Curium/main/Data/Weather.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKxCiCfC3KF1"
      },
      "outputs": [],
      "source": [
        "# Date columns to parse\n",
        "parse_dates = ['Timestamp']\n",
        "\n",
        "# Load CSV files into the Notebook\n",
        "weather_df = pd.read_csv(WEATHER_FILE)\n",
        "\n",
        "test_df =pd.read_csv(TEST_FILE, parse_dates=parse_dates)\n",
        "\n",
        "train_df = pd.read_csv(TRAIparse_dates=parse_dates)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlOW79hX3KF1"
      },
      "source": [
        "### Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x33Rz7kQ3KF1"
      },
      "outputs": [],
      "source": [
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rNsq_9M3KF2"
      },
      "outputs": [],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POq_zK-s3KF2"
      },
      "outputs": [],
      "source": [
        "weather_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQsxPjiB3KF2"
      },
      "outputs": [],
      "source": [
        "train_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNJ3PGes3KF2"
      },
      "outputs": [],
      "source": [
        "#Checking for missing Values\n",
        "train_df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7n0PjidsKvCN"
      },
      "outputs": [],
      "source": [
        "# Checking the descriptive statistics of the dataset\n",
        "train_df.describe().T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXqUrKmE3KF3"
      },
      "source": [
        "### Data Cleaning\n",
        "\n",
        "- Standardize column names- use snake case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igbLDKBW3KF3"
      },
      "outputs": [],
      "source": [
        "train_df.columns = [col.lower() for col in train_df.columns] # Train\n",
        "\n",
        "test_df.columns = [col.lower() for col in test_df.columns] # Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6D9Fvv5B3KF3"
      },
      "outputs": [],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adAI_P1jGVMB"
      },
      "source": [
        "## 2.0 Visualizations\n",
        "### 2.1 Numericals\n",
        "#### 2.1.1 Univariate Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80WXyacb27N2"
      },
      "outputs": [],
      "source": [
        "# Define the target column\n",
        "target = 'eta'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChCRynG_1ITm"
      },
      "outputs": [],
      "source": [
        "numericals = train_df.select_dtypes(include=['number']).columns.tolist()\n",
        "numericals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nt9bbKujGUbB"
      },
      "outputs": [],
      "source": [
        "# Visualize their distributions\n",
        "for column in train_df[numericals].columns:\n",
        "    fig1 = px.violin(train_df, x=column, box=True)\n",
        "\n",
        "    fig2 = px.histogram(train_df, x=column)\n",
        "\n",
        "    # Create a subplot layout with 1 row and 2 columns\n",
        "    fig = make_subplots(rows=1, cols=2, subplot_titles=(f\"Violin plot of the {column} column\",\n",
        "                                                    f\"Distribution of the {column} column\"))\n",
        "\n",
        "    # Add traces from fig1 to the subplot\n",
        "    for trace in fig1.data:\n",
        "        fig.add_trace(trace, row=1, col=1)\n",
        "\n",
        "    # Add traces from fig2 to the subplot\n",
        "    for trace in fig2.data:\n",
        "        fig.add_trace(trace, row=1, col=2)\n",
        "\n",
        "    # Update layout\n",
        "    fig.update_layout(title_text=f\"Exploring the {column} feature\",\n",
        "                        showlegend=True,\n",
        "                        legend_title_text=target\n",
        "    )\n",
        "\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_IDYde84FsW"
      },
      "outputs": [],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1L-mVJI35Eu"
      },
      "outputs": [],
      "source": [
        "for column in numericals:\n",
        "    # Visualizing the distribution of the numericals in the columns by churn\n",
        "    fig = px.violin(\n",
        "        train_df,\n",
        "        x=column,\n",
        "        box=True,\n",
        "        title=f\"Distribution of the {column} column\"\n",
        "    )\n",
        "\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reliifOO5GuL"
      },
      "outputs": [],
      "source": [
        "fig = px.box(\n",
        "    train_df[['trip_distance', 'eta']],\n",
        "    orientation='h',\n",
        "    title='Distribution of Distance Features in the Dataset'\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4IGRYgjGrYc"
      },
      "outputs": [],
      "source": [
        "fig = px.box(\n",
        "    train_df[['destination_lon', 'origin_lon']],\n",
        "    orientation='h',\n",
        "    title='Distribution of Longitude Features in the Dataset'\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJhKitG26Ga3"
      },
      "outputs": [],
      "source": [
        "fig = px.box(\n",
        "    train_df[['destination_lat', 'origin_lat']],\n",
        "    orientation='h',\n",
        "    title='Distribution of Latitude Features in the Dataset'\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CP5ozm2MMUS"
      },
      "source": [
        "### 2.1.2 Bivariate Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3V_gdxA3vEl"
      },
      "outputs": [],
      "source": [
        "# Relationship between Trip_distance and ETA\n",
        "fig = px.scatter(\n",
        "    train_df,\n",
        "    x='trip_distance',\n",
        "    y='eta',\n",
        "    trendline='ols',\n",
        "    trendline_color_override='red',\n",
        "    title='Trip Distance vs ETA'\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sINpiDO5MkXZ"
      },
      "outputs": [],
      "source": [
        "numeric_correlation_matrix = train_df[numericals].corr()\n",
        "\n",
        "# Create heatmap trace\n",
        "heatmap_trace = go.Heatmap(\n",
        "    z=numeric_correlation_matrix.values,\n",
        "    x=numeric_correlation_matrix.columns,\n",
        "    y=numeric_correlation_matrix.index,\n",
        "    colorbar=dict(title='Correlation coefficient'),\n",
        "    texttemplate='%{z:.3f}',\n",
        ")\n",
        "\n",
        "# Create figure\n",
        "fig = go.Figure(data=[heatmap_trace])\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title='Correlation Matrix Heatmap (Numeric Features)',\n",
        ")\n",
        "\n",
        "# Show plot\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxS4tR5O89SQ"
      },
      "source": [
        "### Key Insights\n",
        "\n",
        "The correlation matrix provided reveals key relationships between geographic coordinates (origin and destination), trip distance, and estimated time of arrival (ETA). The analysis aims to uncover the strength and direction of these relationships, which can inform strategies for optimizing route planning and enhancing the accuracy of ETA predictions.\n",
        "\n",
        "1. **Strong Positive Correlation Between Trip Distance and ETA (0.898):**\n",
        "   - **Observation:** The most significant finding is the strong positive correlation between `trip_distance` and `eta` (0.898). This suggests that as the trip distance increases, the estimated time of arrival also increases, indicating that distance is a primary determinant of ETA.\n",
        "   - **Implication:** This insight highlights the importance of accurate distance calculations in predicting ETAs. Any efforts to improve ETA predictions should prioritize refining distance measurements.\n",
        "\n",
        "2. **Moderate Correlations with Geographic Coordinates:**\n",
        "   - **Origin Latitude and Destination Latitude:**\n",
        "     - `origin_lat` and `destination_lat` exhibit a moderate positive correlation (0.313), indicating that trips tend to run more north-south rather than east-west.\n",
        "     - **Implication:** This could be indicative of the travel patterns within the region, possibly due to geographic or infrastructural factors.\n",
        "   - **Destination Longitude and Origin Longitude:**\n",
        "     - `destination_lon` and `origin_lon` show a slight positive correlation (0.172), reflecting that trips generally align along the longitudinal axis.\n",
        "     - **Implication:** While this correlation is weak, it suggests a slight east-west movement trend, complementing the stronger north-south correlation.\n",
        "\n",
        "3. **Weak Correlations Across Other Variables:**\n",
        "   - **Geographic Coordinates vs. Trip Distance and ETA:**\n",
        "     - The correlations between individual geographic coordinates (latitude and longitude) and `trip_distance` or `eta` are generally weak, with the highest being `destination_lat` and `trip_distance` (0.093).\n",
        "     - **Implication:** This suggests that the specific starting and ending points of a trip (in terms of latitude and longitude) have minimal direct impact on the distance or time required for the trip, possibly due to variations in route choices, traffic conditions, or other factors.\n",
        "\n",
        "4. **Negative Correlations Observed:**\n",
        "   - **Latitude and Longitude Interactions:**\n",
        "     - There are weak negative correlations between `origin_lat` and `origin_lon` (-0.172), as well as between `destination_lat` and `destination_lon` (-0.214). This suggests some degree of geographic dispersion in the origins and destinations.\n",
        "     - **Implication:** These negative correlations may indicate that as one coordinate increases, the other tends to decrease, pointing to a potential spread or diversity in trip start and end points across the region.\n",
        "\n",
        "### Strategic Recommendations\n",
        "\n",
        "1. **Enhance ETA Prediction Models:**\n",
        "   - Given the strong correlation between `trip_distance` and `eta`, improving distance measurement accuracy and integrating real-time traffic data could further refine ETA predictions.\n",
        "\n",
        "2. **Leverage Geographic Insights for Route Optimization:**\n",
        "   - The moderate correlations between latitudes and longitudes suggest potential patterns in travel direction. Leveraging this understanding could aid in optimizing routes and better managing traffic flow.\n",
        "\n",
        "3. **Further Exploration of Geographic Variables:**\n",
        "   - The weak correlations with individual geographic coordinates indicate that additional factors, such as road conditions, traffic signals, or driver behavior, might play a significant role. Investigating these factors could uncover additional opportunities for improving service efficiency.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhrhKmiX-f1v"
      },
      "source": [
        "### 2.1.3 Multivariate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrKPUmGTAEG5"
      },
      "outputs": [],
      "source": [
        "plot_data = train_df[['timestamp', 'eta']].set_index('timestamp')\n",
        "\n",
        "\n",
        "plot_data = plot_data.resample('D')['eta'].sum().reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fvWSUXTAZ8r"
      },
      "outputs": [],
      "source": [
        "fig = calplot(\n",
        "    plot_data,\n",
        "    x='timestamp',\n",
        "    y='eta',\n",
        "    years_title=True,\n",
        "    colorscale='YlGn',\n",
        "    showscale=True,\n",
        "    title='Total eta by calendar days, months, and years',\n",
        "    total_height=400,\n",
        "    start_month=11,\n",
        "    end_month=12,\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAeokTB-Oe8O"
      },
      "source": [
        "### Answering Analytical Business Questions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head(1)"
      ],
      "metadata": {
        "id": "xcPaD15HFpzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "QN.1 What is the impact of trip distance on ETA accuracy? Investigating whether longer or shorter trips have more variance in ETA predictions can help refine the model.\n",
        "    \n"
      ],
      "metadata": {
        "id": "PUDi76MjClVU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mM3Gk6XBFlmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "QN. 2 How do different times of the day affect ETA. Analyzing time-based patterns (e.g., rush hours vs. non-rush hours) can help improve the predictive model.\n",
        "    "
      ],
      "metadata": {
        "id": "RzGFESn-C8l5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HovkKfG8Q4ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfreK8qcOney"
      },
      "source": [
        "QN. 3 How does weather impact the estimated time of arrival (ETA) for Yassir trips?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7w6-XVIaYGcG"
      },
      "outputs": [],
      "source": [
        "time_eta_df = train_df[['timestamp', 'eta']]\n",
        "\n",
        "time_eta_df['date'] = time_eta_df['timestamp'].dt.date\n",
        "\n",
        "time_eta_df['date'] = pd.to_datetime(time_eta_df['date'])\n",
        "\n",
        "time_eta_df['eta_hours'] = time_eta_df['eta'] / 3600\n",
        "\n",
        "weather_df['date'] = pd.to_datetime(weather_df['date'])\n",
        "\n",
        "# Merge trip data with weather data\n",
        "merged_df = pd.merge(time_eta_df, weather_df, left_on='date', right_on='date')\n",
        "\n",
        "# Drop unnecessary columns\n",
        "merged_df.drop(columns=['timestamp', 'eta', 'date'], inplace=True)\n",
        "\n",
        "# Show the merged DataFrame\n",
        "merged_df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pairplot of ETA vs Temperature features"
      ],
      "metadata": {
        "id": "Uj9DgkcZ-yqz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THKDbI6l2eXB"
      },
      "outputs": [],
      "source": [
        "# Select the columns to use\n",
        "cols_to_interest = merged_df.columns.tolist()\n",
        "\n",
        "temp_features = [col for col in merged_df.columns.to_list() if 'temperature' in col] + ['eta_hours']\n",
        "\n",
        "# Create the pair plot\n",
        "fig = px.scatter_matrix(\n",
        "    merged_df,\n",
        "    dimensions = temp_features,\n",
        "\n",
        ")\n",
        "\n",
        "# Update the layout for better visualization\n",
        "fig.update_layout(\n",
        "    title=f\"Pair Plot of {', '.join(temp_features)} columns\",\n",
        "    width=1440,\n",
        "    height=1440,\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pairplot of ETA vs other Weather features"
      ],
      "metadata": {
        "id": "KQipjUMG_FJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "other_features = [col for col in merged_df.columns.to_list() if 'temperature' not in col]\n",
        "\n",
        "# Create the pair plot\n",
        "fig = px.scatter_matrix(\n",
        "    merged_df,\n",
        "    dimensions = other_features,\n",
        "\n",
        ")\n",
        "\n",
        "# Update the layout for better visualization\n",
        "fig.update_layout(\n",
        "    title=f\"Pair Plot of {', '.join(other_features)} columns\",\n",
        "    width=1440,\n",
        "    height=1440,\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "rH4pwpFD_KfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "QN. 4 What are the peak hours for long trip durations and how can they be optimized?\n",
        "    "
      ],
      "metadata": {
        "id": "eQyKpcAPDG7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trip_duration = train_df[['timestamp', 'eta']]\n",
        "\n",
        "trip_duration['eta_hours'] = trip_duration['eta']/3600\n",
        "\n",
        "trip_duration['hour'] = trip_duration['timestamp'].dt.hour\n",
        "\n",
        "# Calculate average ETA by hour\n",
        "average_eta_by_hour = trip_duration.groupby('hour')['eta_hours'].mean().reset_index()\n",
        "\n",
        "#Calculate the count of ETA by hour\n",
        "count_eta_by_hour = trip_duration.groupby('hour')['eta_hours'].count().reset_index()\n",
        "\n",
        "# Plot count ETA by hour\n",
        "fig = px.line(count_eta_by_hour, x='hour', y='eta_hours', title='Count ETA by Hour of the Day')\n",
        "\n",
        "fig.show()\n",
        "\n",
        "\n",
        "# Plot average ETA by hour\n",
        "fig = px.line(average_eta_by_hour, x='hour', y='eta_hours', title='Average ETA by Hour of the Day')\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "y7iPP_O6Ji_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Observations\n"
      ],
      "metadata": {
        "id": "xJqHTh0qRU_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "QN. 5 Is there a significant difference in trip durations between weekdays and weekends?\n",
        "    "
      ],
      "metadata": {
        "id": "EyQ3TPF4DPue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "day_eta_df = train_df[['timestamp', 'eta']]\n",
        "\n",
        "day_eta_df['eta_hours'] = day_eta_df['eta']/3600\n",
        "\n",
        "day_eta_df['day_of_week'] = day_eta_df['timestamp'].dt.day_name()\n",
        "\n",
        "category_orders={\"day_of_week\": [\"Saturday\", \"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\"]}\n",
        "\n",
        "# Boxplot of ETA by Day of the Week\n",
        "fig = px.box(day_eta_df, x='day_of_week', y='eta_hours',  title = 'ETA by Day of the Week', category_orders = category_orders)\n",
        "fig.show()\n",
        "\n",
        "# Calculate average ETA by day of the week\n",
        "average_eta_by_day = day_eta_df.groupby('day_of_week')['eta_hours'].mean().reset_index()\n",
        "\n",
        "\n",
        "# Create a Plotly line chart\n",
        "fig = px.line(average_eta_by_day, x='day_of_week', y='eta_hours', title='Average ETA by Day of the Week')\n",
        "\n",
        " # Update x-axis to have correct day names\n",
        "fig.update_layout( xaxis_title='Day of the Week',  yaxis_title='Average ETA (hours)')\n",
        "# Show the plot\n",
        "fig.show()\n",
        "\n",
        "\n",
        "# Define weekdays (Sunday to Thursday) and weekends (Friday and Saturday)\n",
        "weekends_list = ['Friday','Saturday']\n",
        "\n",
        "mask = day_eta_df['day_of_week'].isin(weekends_list)\n",
        "\n",
        "weekdays = day_eta_df[~mask]['eta_hours']\n",
        "weekends = day_eta_df[mask]['eta_hours']\n",
        "\n",
        "# Perform t-test\n",
        "t_stat, p_value = ttest_ind(weekdays, weekends)\n",
        "print(f\"T-statistic: {t_stat}, P-value: {p_value}\")\n",
        "\n",
        "# Conclusion\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference in trip durations between weekdays and weekends.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant difference in trip durations between weekdays and weekends.\")"
      ],
      "metadata": {
        "id": "--1JvOhHJ1Is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "QN. 6 How does the density of trips in a given area affect the performance of the ETA prediction?\n",
        "    "
      ],
      "metadata": {
        "id": "IXKeOsExDUx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to categorize coordinates into grids\n",
        "def categorize_area(lat, lon, grid_size=0.1):\n",
        "    return (round(lat / grid_size) * grid_size, round(lon / grid_size) * grid_size)\n",
        "\n",
        "# Create a new dataframe to be used\n",
        "trip_density_df = train_df[['origin_lat','origin_lon','destination_lat','destination_lon','eta','trip_distance']]\n",
        "\n",
        "# Apply the function to create a new 'area' column\n",
        "trip_density_df['origin_area'] = trip_density_df.apply(lambda row: categorize_area(row['origin_lat'], row['origin_lon']), axis=1)\n",
        "trip_density_df['destination_area'] = trip_density_df.apply(lambda row: categorize_area(row['destination_lat'], row['destination_lon']), axis=1)\n",
        "trip_density_df.head(1)"
      ],
      "metadata": {
        "id": "iMCRnzxfLmid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "QN. 7 How does the model's ETA prediction accuracy compare to industry benchmarks or competitors?"
      ],
      "metadata": {
        "id": "HqLSOaejDbiN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Qn. 8 How does the time of day influence the demand for Yassir rides in different geographical areas?"
      ],
      "metadata": {
        "id": "Y9BvS5DBDgNj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "QN. 9 Which origin and destination locations are most common?/Have the most rides"
      ],
      "metadata": {
        "id": "S2otsLee1BUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by origin locations and count occurrences\n",
        "origin_counts = train_df.groupby(['origin_lat', 'origin_lon'])['origin_lon'].count().reset_index(name='count')\n",
        "\n",
        "# Sort by count in descending order\n",
        "most_common_origins = origin_counts.sort_values(by='count', ascending=False).head(10)\n",
        "\n",
        "# Group by destination locations and count occurrences\n",
        "destination_counts = train_df.groupby(['destination_lat', 'destination_lon'])['destination_lon'].count().reset_index(name='count')\n",
        "\n",
        "# Sort by count in descending order\n",
        "most_common_destinations = destination_counts.sort_values(by='count', ascending=False).head(10)\n",
        "most_common_origins"
      ],
      "metadata": {
        "id": "t29nvj8o1E8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create subplots\n",
        "fig = make_subplots(rows=1, cols=2, subplot_titles=('Top 10 Most Common Origin Locations', 'Top 10 Most Common Destination Locations'))\n",
        "\n",
        "# Prepare data for origin locations\n",
        "most_common_origins['location'] = most_common_origins.apply(lambda row: f\"({row['origin_lat']}, {row['origin_lon']})\", axis=1)\n",
        "\n",
        "# Add trace for origin locations\n",
        "fig.add_trace(\n",
        "    go.Bar(x=most_common_origins['location'], y=most_common_origins['count'],\n",
        "           name='Origin Locations'),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "# Prepare data for destination locations\n",
        "most_common_destinations['location'] = most_common_destinations.apply(lambda row: f\"({row['destination_lat']}, {row['destination_lon']})\", axis=1)\n",
        "\n",
        "# Add trace for destination locations\n",
        "fig.add_trace(\n",
        "    go.Bar(x=most_common_destinations['location'], y=most_common_destinations['count'],\n",
        "           name='Destination Locations'),\n",
        "    row=1, col=2\n",
        ")\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title_text='Top 10 Most Common Origin and Destination Locations',\n",
        "    xaxis_title='Origin Locations',\n",
        "    yaxis_title='Number of Rides',\n",
        "    xaxis2_title='Destination Locations',\n",
        "    yaxis2_title='Number of Rides',\n",
        "    xaxis_tickangle=-45,\n",
        "    xaxis2_tickangle=-45,\n",
        "    showlegend=False\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "4z6BtjYL23Jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "QN. 10 What are the top 10 longest and top 10 shortest trips, and how do their ETAs compare?"
      ],
      "metadata": {
        "id": "xhy6vFtx6JSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head(1)"
      ],
      "metadata": {
        "id": "t-9m7-JDDv38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the 10 largest trip distances (shortest)\n",
        "short_trips = train_df[['trip_distance','eta']].nsmallest(10, 'trip_distance').rename(columns={'trip_distance': 'short_trip_distance'})\n",
        "\n",
        "# Get the 10 smallest trip distances (longest)\n",
        "long_trips = train_df[['trip_distance','eta']].nlargest(10, 'trip_distance').rename(columns={'trip_distance': 'long_trip_distance'})\n",
        "\n",
        "fig = px.line(short_trips, x='short_trip_distance', y='eta')\n",
        "fig.show()\n",
        "\n",
        "fig = px.line(long_trips, x='long_trip_distance', y='eta')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "Z52uhj7iNOlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "QN. 11 What is the percentage of trips with ETAs exceeding 30 minutes."
      ],
      "metadata": {
        "id": "CijJuoTu7TVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eta_df = train_df['eta_hours'] = train_df['ETA'] / 3600\n",
        "\n",
        "# Create a dataframe for ETA values\n",
        "eta_df = train_df[['eta_hours']]\n",
        "\n",
        "# Convert ETA to minutes\n",
        "eta_df['eta_minutes'] = eta_df['eta_hours'] * 60\n",
        "\n",
        "# Filter trips with ETAs exceeding 30 minutes\n",
        "long_trips = eta_df[eta_df['eta_minutes'] > 30]\n",
        "\n",
        "# Count the number of trips with ETAs exceeding 30 minutes\n",
        "num_long_trips = len(long_trips)\n",
        "\n",
        "# Calculate the total number of trips\n",
        "total_trips = len(eta_df)\n",
        "\n",
        "# Calculate the percentage of trips with ETAs exceeding 30 minutes\n",
        "percentage_long_trips = (num_long_trips / total_trips) * 100\n",
        "\n",
        "# Create a summary dataframe\n",
        "summary_df = pd.DataFrame({\n",
        "    'Total Trips': [total_trips],\n",
        "    'Trips > 30 min': [num_long_trips],\n",
        "    'Percentage > 30 min': [percentage_long_trips]\n",
        "})\n",
        "summary_df"
      ],
      "metadata": {
        "id": "DQnGkCFcALq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create labels and values for the pie chart\n",
        "labels = ['Trips > 30 min', 'Trips <= 30 min']\n",
        "values = [num_long_trips, total_trips - num_long_trips]\n",
        "\n",
        "# Create a pie chart using Plotly\n",
        "fig = go.Figure(data=[go.Pie(labels=labels, values=values,\n",
        "                             insidetextorientation='radial', marker=dict(colors=['crimson', 'lightblue']))])\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title='Percentage of Trips with ETAs Exceeding 30 Minutes'\n",
        ")\n",
        "# Show plot\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "jkLJiBVBJRJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "QN. 12 What is the average number of trips per hour?"
      ],
      "metadata": {
        "id": "P2Cjmrs6BFrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataframe for Timestamp\n",
        "time_df = train_df[['Timestamp']]\n",
        "\n",
        "# Extract the hour from the timestamp\n",
        "time_df['hour'] = time_df['Timestamp'].dt.hour\n",
        "\n",
        "# Count the number of trips for each hour\n",
        "trips_per_hour = time_df['hour'].value_counts().sort_index().reset_index().rename(columns={'hour': 'Hour', 'count': 'Number of Trips'})\n",
        "\n",
        "ave_trips_per_hour = trips_per_hour.groupby('Hour')['Number of Trips'].mean().reset_index()\n",
        "ave_trips_per_hour"
      ],
      "metadata": {
        "id": "RCEa9ik4B_94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot count ETA by hour\n",
        "fig = px.line(ave_trips_per_hour, x='Hour', y='Number of Trips', title='Average number of trips by Hour')\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "KASOjh_CFhIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Hypothesis"
      ],
      "metadata": {
        "id": "3TnkFaEA5_Ex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha=0.05"
      ],
      "metadata": {
        "id": "Ceo8ZKkawn3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normality test- Using Shapiro-Wilk test"
      ],
      "metadata": {
        "id": "bq9hmK-vu7F1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numericals = train_df.select_dtypes(include='number').columns.to_list()\n",
        "for c in numericals:\n",
        "  print([c])\n",
        "  a, b = shapiro(train_df[[c]])\n",
        "  print(f'Statistics: {a}, p-value: b')\n",
        "\n",
        "  if b < alpha:\n",
        "    print('The distribution is not normal')\n",
        "  else:\n",
        "    print('The distribution is normal')"
      ],
      "metadata": {
        "id": "zo7HUTauu6U-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "week_eta_df = train_df[['timestamp', 'eta']]\n",
        "\n",
        "week_eta_df['eta_hours'] = week_eta_df['eta']/3600\n",
        "\n",
        "week_eta_df['day_of_week'] = week_eta_df['timestamp'].dt.day_name()\n",
        "\n",
        "# Define weekdays (Sunday to Thursday) and weekends (Friday and Saturday)\n",
        "weekends_list = ['Friday','Saturday']\n",
        "\n",
        "mask = week_eta_df['day_of_week'].isin(weekends_list)\n",
        "\n",
        "weekdays = day_eta_df[~mask]['eta_hours']\n",
        "weekends = day_eta_df[mask]['eta_hours']\n",
        "\n",
        "\n",
        "# Perform Mann-Whitney U test\n",
        "u_statistic, p_value = mannwhitneyu(weekdays, weekends, alternative='two-sided', nan_policy='omit')\n",
        "\n",
        "# Print the results\n",
        "print(\"Mann-Whitney U Test Results:\")\n",
        "print(f\"U-statistic: {u_statistic}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Conclusion\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference in trip durations between weekdays and weekends.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant difference in trip durations between weekdays and weekends.\")"
      ],
      "metadata": {
        "id": "oXhSRToz6Hqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This finding suggests that the behavior of trip durations varies notably depending on the day of the week, with implications for operational efficiency and customer experience.\n",
        "\n",
        "### Key Findings\n",
        "\n",
        "- **Statistical Insight**: The Mann-Whitney U test yielded a U-statistic of 721,718,033.5 with a p-value of 3.81e-06, well below the conventional significance level of 0.05. This leads to a rejection of the null hypothesis, confirming that trip durations differ significantly between weekdays and weekends.\n",
        "  \n",
        "- **Operational Impact**: The significant variation in trip durations highlights potential inefficiencies in resource allocation. Weekends may see either longer or shorter trips due to differences in traffic patterns, rider behavior, or demand fluctuations. If trip durations are longer on weekends, this could lead to increased operational costs and reduced fleet availability. Conversely, shorter durations could indicate underutilization of resources, presenting an opportunity to optimize service levels.\n",
        "\n",
        "- **Customer Experience**: Discrepancies in trip durations across different days could impact customer satisfaction. Longer trip durations on weekends may lead to delays and dissatisfaction, particularly if expectations are set based on weekday performance. Consistency in ETA is crucial for maintaining customer trust and satisfaction, so addressing these discrepancies could enhance the overall customer experience.\n",
        "\n",
        "### Business Impact\n",
        "\n",
        "1. **Resource Optimization**: Understanding the differences in trip durations allows for better resource allocation. For example, if weekend trips are typically longer, the business might need to deploy more vehicles or adjust driver schedules to meet demand and reduce wait times. This optimization can lead to cost savings and improved service reliability.\n",
        "\n",
        "2. **Demand Forecasting**: The significant difference in trip durations suggests that demand patterns vary between weekdays and weekends. Leveraging this insight can improve demand forecasting models, allowing for more accurate predictions and better planning.\n",
        "\n",
        "3. **Service Level Adjustments**: To address customer dissatisfaction due to longer trip durations on weekends, the business could explore dynamic pricing, offering incentives for off-peak travel, or adjusting service levels to ensure faster service during peak times.\n",
        "\n",
        "### Opportunities\n",
        "\n",
        "- **Targeted Marketing**: The data indicates an opportunity for targeted marketing campaigns aimed at smoothing out demand across the week. For instance, offering promotions for weekend travel during off-peak hours could help balance demand and reduce pressure on resources during peak times.\n",
        "\n",
        "- **Data-Driven Strategy**: With clear evidence of differing trip durations, the business has an opportunity to adopt a more data-driven approach to operations. This could involve using real-time data to adjust fleet deployment dynamically, ensuring optimal service levels throughout the week.\n",
        "\n",
        "- **Customer Communication**: Enhancing communication with customers regarding expected trip durations on different days could manage expectations and improve satisfaction. Transparent communication about potential delays on weekends, along with proactive measures to mitigate them, could strengthen customer trust.\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "The significant difference in trip durations between weekdays and weekends presents both challenges and opportunities for the business. By optimizing resource allocation, refining demand forecasting, and enhancing customer communication, the company can not only mitigate potential negative impacts but also unlock new avenues for growth and efficiency. Adopting these strategies will position the business to deliver a more consistent and satisfying customer experience while maintaining operational excellence."
      ],
      "metadata": {
        "id": "3Ibq0OWzA5zv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplot of ETA by Day of the Week\n",
        "fig = make_subplots(rows=1, cols=2, subplot_titles=('ETA weekdays', 'ETA weekends'))\n",
        "fig.add_trace(\n",
        "    go.Box(y=weekdays,\n",
        "           name='Weekdays'),\n",
        "    row=1, col=1\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Box(y=weekends,\n",
        "           name='Weekends'),\n",
        "    row=1, col=2\n",
        ")\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title_text='Trip durations between weekdays and weekends',\n",
        "    yaxis_title='ETA (hours)',\n",
        "    yaxis2_title='ETA (hours)',\n",
        "    showlegend=False\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "P2Oe6SBT2G-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wk_df = train_df[['timestamp', 'eta']]\n",
        "\n",
        "wk_df['day_type'] = ['Weekend' if wk_day in [4, 5] else 'Weekday' for wk_day in wk_df['timestamp'].dt.weekday ]\n",
        "\n",
        "wk_df['eta_hours'] = week_eta_df['eta']/3600\n",
        "\n",
        "# Add a month column for monthly trend analysis\n",
        "wk_df['month'] = wk_df['timestamp'].dt.month_name()\n",
        "\n",
        "# Calculate average trip duration per day type per month\n",
        "trend_df = wk_df.groupby(['month', 'day_type']).agg({'eta_hours': 'median'}).reset_index()\n",
        "\n",
        "# Plot the trend using Plotly\n",
        "fig = px.line(trend_df, x='month', y='eta_hours', color='day_type',\n",
        "              title='Trend of Median Trip Duration over Time',\n",
        "              labels={'eta_hours': 'Median Trip Duration (hours)', 'month': 'Month'},\n",
        "              markers=True)\n",
        "\n",
        "# Customize the plot\n",
        "fig.update_layout(xaxis_title='Month',\n",
        "                  yaxis_title='Median Trip Duration (hours)',\n",
        "                  legend_title='Day Type',\n",
        "                  hovermode='x unified')\n",
        "\n",
        "# Show the plot\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "lTWeVlrx3xou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The median values indicate that, while statistically significant, the practical difference between weekdays and weekends is subtle. This finding suggests opportunities for fine-tuning operations and enhancing customer satisfaction.\n",
        "\n",
        "### Key Findings\n",
        "\n",
        "- **ETA Variation**: The data shows that the median ETA is slightly longer on weekdays compared to weekends for both November and December.\n",
        "  - **December**: The median ETA on weekdays is 0.295 hours, compared to 0.288 hours on weekends.\n",
        "  - **November**: The median ETA on weekdays is 0.294 hours, compared to 0.289 hours on weekends.\n",
        "\n",
        "- **Consistency Across Months**: The pattern of longer weekday ETAs is consistent across both months, indicating a persistent trend rather than random variability.\n",
        "\n",
        "### Business Impact\n",
        "\n",
        "- **Operational Efficiency**: The slight increase in median ETA on weekdays suggests potential inefficiencies, such as higher traffic or demand during these periods. Addressing these factors could lead to improvements in operational performance.\n",
        "\n",
        "- **Customer Experience**: Even small differences in median ETA can influence customer perceptions, especially during high-demand periods. Ensuring more consistent ETAs across the week could enhance overall customer satisfaction.\n",
        "\n",
        "- **Predictable Patterns**: The consistency of these differences across months suggests that these trends are predictable, allowing the business to anticipate and plan for varying demand and traffic conditions.\n",
        "\n",
        "### Opportunities\n",
        "\n",
        "- **Route Optimization**: Given the consistent yet small difference in median ETAs, there's an opportunity to optimize routes specifically for weekdays. Adjustments could be made to minimize delays and improve trip efficiency during these peak times.\n",
        "\n",
        "- **Enhanced Demand Forecasting**: The median-based analysis supports the development of more refined demand forecasting models that account for day-of-week variations. This can lead to better resource allocation and improved service reliability.\n",
        "\n",
        "- **Customer Communication Strategies**: Clear communication with customers about potential weekday delays, coupled with targeted incentives for off-peak travel, could help manage expectations and maintain customer loyalty.\n",
        "\n",
        "\n",
        "The significant difference in median trip durations between weekdays and weekends, while statistically notable, is relatively modest. This suggests room for operational improvements that could further reduce ETAs, particularly during weekdays. By leveraging these insights, the business can optimize its operations and enhance customer satisfaction, ensuring a more consistent and reliable service."
      ],
      "metadata": {
        "id": "kLUK7T88Bpl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head(1)"
      ],
      "metadata": {
        "id": "tMWRaa_VQc9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-ba0qWc3KF4"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Divide the Dataset into X and y variables"
      ],
      "metadata": {
        "id": "XqTyFa0pQMzC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nLQlim2_TTU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nZgspC69mtiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_df.drop('eta', axis=1)\n",
        "y = train_df['eta']\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=20, random_state=42)"
      ],
      "metadata": {
        "id": "AoZCMGSRNPet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing Pipelines"
      ],
      "metadata": {
        "id": "xrLb8Cx9eRNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_columns = X.select_dtypes('number').columns\n",
        "numerical_columns"
      ],
      "metadata": {
        "id": "py7_I0vOUeyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_pipeline = Pipeline(steps=[\n",
        "    ('num_imputer', SimpleImputer(strategy = 'median')),\n",
        "     ('num_scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', numerical_pipeline, numerical_columns)],\n",
        "      remainder='drop'\n",
        "                                 )\n"
      ],
      "metadata": {
        "id": "BKmRbgvOc9pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor.fit_transform(X_train)"
      ],
      "metadata": {
        "id": "rb_HYOvr37Pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmfkhj6t3KF4"
      },
      "source": [
        "# Modeling and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models =[\n",
        "    ('Decision_tree', DecisionTreeRegressor(random_state=42)),\n",
        "    ('Logistic_reg', LogisticRegression(random_state=42)),\n",
        "    ('Linear_reg', LinearRegression()),\n",
        "    ('random_forest', RandomForestRegressor(random_state = 42)),\n",
        "    ('xgboost_reg',XGBRegressor(random_state = 42))\n",
        "\n",
        "]\n",
        "\n",
        "# Dictionary to store predictions and errors\n",
        "all_pipelines = {}\n",
        "# results = {}\n",
        "# Create an empty DataFrame for metrics\n",
        "metrics_table = pd.DataFrame(columns=['NAME', 'MSE', 'RMSE'])\n",
        "# Train and predict with each model\n",
        "for name, model in models:\n",
        "  final_pipeline = Pipeline(steps=[\n",
        "      ('preprocessor', preprocessor),\n",
        "      ('regressor', model)\n",
        "  ])\n",
        "  final_pipeline.fit(X_train, y_train)\n",
        "  y_pred = final_pipeline.predict(X_test)\n",
        "  mse = mean_squared_error(y_test, y_pred)\n",
        "  rmse = np.sqrt(mse)\n",
        "  # results[name] = {'Predictions': y_pred, 'Root Mean Squared Error': rmse }\n",
        "  # Calculate the Root Mean Squared Logarithmic Error (RMSLE)\n",
        "  # rmsle = root_mean_squared_log_error(y_eval, y_pred_abs)\n",
        "\n",
        "    # Add all pipelines into all_pipeline dictionary\n",
        "  all_pipelines[name] = final_pipeline\n",
        "\n",
        "    # Add metrics to metrics_table\n",
        "  metrics_table.loc[len(metrics_table)] = [name, mse, rmse]\n",
        "\n",
        "# # Print results\n",
        "# for name, result in results.items():\n",
        "#   print(f\"Model: {name}\")\n",
        "#   print(f\"Root Mean Squared Error: {result['Root Mean Squared Error']:.2f}\")\n",
        "#   print(f\"First 5 Predictions: {result['Predictions'][:5]}\")\n",
        "#   print()\n"
      ],
      "metadata": {
        "id": "a7_IXf7Eefvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the metrics table\n",
        "metrics_table = metrics_table.sort_values(ascending=True, by='RMSE').reset_index().drop(columns='index')\n",
        "metrics_table"
      ],
      "metadata": {
        "id": "O96TRToBBt8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_name = metrics_table['NAME'].iloc[0]\n",
        "best_model_name"
      ],
      "metadata": {
        "id": "Nl9kzrNQB1A_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = all_pipelines.get(best_model_name)\n",
        "best_model"
      ],
      "metadata": {
        "id": "95HISxD5JlaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Get the numerical feature names after transformation\n",
        "# numerical_features_transformed = best_model.named_steps['preprocessor'].named_transformers_['num'].named_steps['num_scaler'].get_feature_names_out(['onpromotion', 'year', 'is_year_start',\n",
        "#        'quarter', 'is_quarter_start', 'is_quarter_end', 'month',\n",
        "#        'is_month_start', 'is_month_end', 'week_of_year', 'is_weekend',\n",
        "#        'day_of_year', 'day_of_month', 'day_of_week'])\n",
        "# numerical_features_transformed"
      ],
      "metadata": {
        "id": "DUtUCB0eKoYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Get the feature names after transformation\n",
        "# feature_columns = np.concatenate((numerical_features_transformed))\n",
        "# score = best_model.named_steps['regressor'].feature_importances_\n",
        "\n",
        "# # Display the feature columns\n",
        "# f_importances_df = pd.DataFrame({'Feature':feature_columns, 'Score': score})\n",
        "# f_importances_df.sort_values(by='Score', ascending = False, inplace=True)\n",
        "# f_importances_df"
      ],
      "metadata": {
        "id": "HMVrGo4BKnQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare Test Dataset"
      ],
      "metadata": {
        "id": "BcefSVx7LOh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "metadata": {
        "id": "2lmliYdRKlrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# eta_pred = best_model.predict(test_df)"
      ],
      "metadata": {
        "id": "EMver-u0L0de"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# submission_df = pd.DataFrame(\n",
        "#     {\n",
        "#         'id': test_df['id'],\n",
        "#         'eta': eta_pred\n",
        "#     }\n",
        "# )\n",
        "# submission_df"
      ],
      "metadata": {
        "id": "xB2W66qYMB33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Persist/Saving the Model"
      ],
      "metadata": {
        "id": "zazfv6yzMfdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for model_name, model in {**all_stat_models, **all_pipelines}.items():\n",
        "#     joblib.dump(model,f'./Trained models/{model_name}.joblib')"
      ],
      "metadata": {
        "id": "7kQfReu3MBLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFBb26Fh3KF5"
      },
      "source": [
        "# Deployment"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}